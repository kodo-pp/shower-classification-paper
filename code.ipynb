{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c059fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tqdm.notebook\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f321198",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'eplus': h5py.File('data/eplus_angle_position_5deg_xy.h5'),\n",
    "    'piplus': h5py.File('data/piplus_angle_position_5deg_xy.h5'),\n",
    "    'gamma': h5py.File('data/gamma_angle_position_5deg_xy.h5'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb84831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be run on a GPU (CUDA/HIP)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Models will be run on a GPU (CUDA/HIP)')\n",
    "    dev = torch.device('cuda')\n",
    "else:\n",
    "    print('Models will be run on a CPU')\n",
    "    dev = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e2934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sizes(size_a: int, size_b: int, num_samples: int) -> Tuple[int, int]:\n",
    "    num_a_samples = min(\n",
    "        np.random.binomial(num_samples, size_a / (size_a + size_b)),\n",
    "        size_a,\n",
    "    )\n",
    "    num_b_samples = min(num_samples - num_a_samples, size_b)\n",
    "    num_a_samples = min(num_samples - num_b_samples, size_a)\n",
    "    assert num_a_samples + num_b_samples == min(num_samples, size_a + size_b)\n",
    "    return num_a_samples, num_b_samples\n",
    "\n",
    "class SamplerEpoch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_a_indices: int,\n",
    "        num_b_indices: int,\n",
    "        minibatch_size: int,\n",
    "        id: Optional[int],\n",
    "        cursor_a: int = 0,\n",
    "        cursor_b: int = 0\n",
    "    ) -> None:\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.id = id\n",
    "        self.num_a_indices = num_a_indices\n",
    "        self.num_b_indices = num_b_indices\n",
    "        self.initial_cursor_a = cursor_a\n",
    "        self.initial_cursor_b = cursor_b\n",
    "        self.cursor_a = cursor_a\n",
    "        self.cursor_b = cursor_b\n",
    "    \n",
    "    def __iter__(self) -> 'SamplerEpoch':\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        num_a_items_left = self.num_a_indices - self.cursor_a\n",
    "        num_b_items_left = self.num_b_indices - self.cursor_b\n",
    "        assert num_a_items_left >= 0\n",
    "        assert num_b_items_left >= 0\n",
    "        \n",
    "        if num_a_items_left == num_b_items_left == 0:\n",
    "            raise StopIteration()\n",
    "\n",
    "        num_a_items, num_b_items = sample_sizes(\n",
    "            num_a_items_left,\n",
    "            num_b_items_left,\n",
    "            self.minibatch_size,\n",
    "        )\n",
    "        \n",
    "        begin_a = self.cursor_a\n",
    "        end_a = begin_a + num_a_items\n",
    "        begin_b = self.cursor_b\n",
    "        end_b = begin_b + num_b_items\n",
    "        \n",
    "        self.cursor_a = end_a\n",
    "        self.cursor_b = end_b\n",
    "        # Only the last mini-batch may be incomplete.\n",
    "        assert num_a_items + num_b_items == self.minibatch_size or (\n",
    "            self.cursor_a == self.num_a_indices\n",
    "            and self.cursor_b == self.num_b_indices\n",
    "        )\n",
    "        return (begin_a, end_a), (begin_b, end_b)\n",
    "    \n",
    "    def __len__(self):\n",
    "        num_indices = self.num_a_indices + self.num_b_indices - self.initial_cursor_a - self.initial_cursor_b\n",
    "        batch = self.minibatch_size\n",
    "        return (num_indices + batch - 1) // batch\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f'SamplerEpoch(id={self.id}), '\n",
    "            f'minibatch_size={self.minibatch_size}, '\n",
    "            f'num_indices=({self.num_a_indices}, {self.num_b_indices}), '\n",
    "            f'cursor=({self.cursor_a}, {self.cursor_b}))'\n",
    "        )\n",
    "\n",
    "class Sampler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_samples_a: int,\n",
    "        num_samples_b: int,\n",
    "        minibatch_size: int,\n",
    "        cv_split: float,\n",
    "    ) -> None:\n",
    "        while True:\n",
    "            num_cv_indices_a = round(num_samples_a * cv_split)\n",
    "            num_cv_indices_b = round(num_samples_b * cv_split)\n",
    "            self.cv_start_a = num_samples_a - num_cv_indices_a\n",
    "            self.cv_start_b = num_samples_b - num_cv_indices_b\n",
    "            if (self.cv_start_a + self.cv_start_b) % minibatch_size == 1:\n",
    "                cv_split *= 0.9999\n",
    "            else:\n",
    "                break\n",
    "        self.num_samples_a = num_samples_a\n",
    "        self.num_samples_b = num_samples_b\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.num_epochs = 0\n",
    "    \n",
    "    def epoch(self) -> SamplerEpoch:\n",
    "        self.num_epochs += 1\n",
    "        return SamplerEpoch(\n",
    "            self.cv_start_a,\n",
    "            self.cv_start_a,\n",
    "            minibatch_size=self.minibatch_size,\n",
    "            id=self.num_epochs,\n",
    "        )\n",
    "    \n",
    "    def cv(self) -> SamplerEpoch:\n",
    "        return SamplerEpoch(\n",
    "            self.num_samples_a,\n",
    "            self.num_samples_b,\n",
    "            minibatch_size=self.minibatch_size,\n",
    "            id=None,\n",
    "            cursor_a=self.cv_start_a,\n",
    "            cursor_b=self.cv_start_b,\n",
    "        )\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f'Sampler(cv_start=({self.cv_start_a}, {self.cv_start_b}), '\n",
    "            f'num_samples=({self.num_samples_a}, {self.num_samples_b}), '\n",
    "            f'minibatch_size={self.minibatch_size}, '\n",
    "            f'self.num_epochs={self.num_epochs})'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "794b443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def get_layers(data_file: h5py.File, begin: int, end: int) -> List[np.ndarray]:\n",
    "    layers = []\n",
    "    for i in range(3):\n",
    "        layer = data_file[f'layer_{i}']\n",
    "        layer_part = layer[begin:end]\n",
    "        layers.append(layer_part)\n",
    "    return layers\n",
    "\n",
    "def flatten_layers(data_file: h5py.File, begin: int, end: int) -> np.ndarray:\n",
    "    layers = get_layers(data_file, begin, end)\n",
    "    \n",
    "    for i, layer in enumerate(layers):\n",
    "        feature_size = reduce(lambda a, b: a * b, layer.shape[1:])\n",
    "        reshaped = layer.reshape((layer.shape[0], feature_size))\n",
    "        layers[i] = reshaped\n",
    "        \n",
    "    return np.hstack(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7feb0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod, ABC\n",
    "\n",
    "class BaseModel(torch.nn.Module, ABC):\n",
    "    @abstractmethod\n",
    "    def prepare_input(\n",
    "        self,\n",
    "        data_a: h5py.File,\n",
    "        data_b: h5py.File,\n",
    "        begin_a: int,\n",
    "        end_a: int,\n",
    "        begin_b: int,\n",
    "        end_b: int,\n",
    "    ) -> Tuple[Any, torch.Tensor]:\n",
    "        \"\"\"Prepare input data from the dataset slices and return tensors `X` and `y` on `dev`.\"\"\"\n",
    "        ...\n",
    "    \n",
    "    @abstractmethod\n",
    "    def description(self) -> str:\n",
    "        \"\"\"Briefly describe this model.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7419fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFcPixel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            self.make_layer(504, 512),\n",
    "            self.make_layer(512, 1024),\n",
    "            self.make_layer(1024, 2048),\n",
    "            self.make_layer(2048, 1024),\n",
    "            self.make_layer(1024, 128),\n",
    "            torch.nn.Linear(128, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_layer(num_in, num_out):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_in, num_out),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.BatchNorm1d(num_out),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(\n",
    "        data_a: h5py.File,\n",
    "        data_b: h5py.File,\n",
    "        begin_a: int,\n",
    "        end_a: int,\n",
    "        begin_b: int,\n",
    "        end_b: int,\n",
    "    ) -> Tuple[Any, torch.Tensor]:\n",
    "        x_a = flatten_layers(data_a, begin_a, end_a)\n",
    "        x_b = flatten_layers(data_b, begin_b, end_b)\n",
    "        x = torch.Tensor(np.vstack([x_a, x_b])).to(dev)\n",
    "        y = torch.Tensor([0] * (end_a - begin_a) + [1] * (end_b - begin_b)).to(dev)\n",
    "        return x, y\n",
    "    \n",
    "    @staticmethod\n",
    "    def description() -> str:\n",
    "        return 'FC network on pixel intensities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e55ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssertShape(torch.nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super().__init__()\n",
    "        self.required_shape = torch.Size(shape)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        actual_shape = x.shape[1:]\n",
    "        if actual_shape != self.required_shape:\n",
    "            raise ValueError(f'Invalid shape: expected {self.required_shape}, got {actual_shape}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c3a8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy => (400000, 1)\n",
      "layer_0 => (400000, 3, 96)\n",
      "layer_1 => (400000, 12, 12)\n",
      "layer_2 => (400000, 12, 6)\n",
      "overflow => (400000, 3)\n",
      "px => (400000, 1)\n",
      "py => (400000, 1)\n",
      "pz => (400000, 1)\n",
      "t0 => (400000, 1)\n",
      "x0 => (400000, 1)\n",
      "y0 => (400000, 1)\n",
      "z0 => (400000, 1)\n"
     ]
    }
   ],
   "source": [
    "for key, value in data['eplus'].items():\n",
    "    print(f'{key} => {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96c99cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def move_tensors_to(tensors, device):\n",
    "    shapes = [tensor.shape for tensor in tensors]\n",
    "    all_flat = torch.cat([tensor.flatten() for tensor in tensors], 0)\n",
    "    all_flat = all_flat.to(device)\n",
    "    sizes = [reduce(lambda a, b: a * b, shape) for shape in shapes]\n",
    "    \n",
    "    moved_tensors = []\n",
    "    cumulative_size = 0\n",
    "    for shape, size in zip(shapes, sizes):\n",
    "        new_cumulative_size = cumulative_size + size\n",
    "        flat_tensor = all_flat[cumulative_size:new_cumulative_size]\n",
    "        moved_tensors.append(flat_tensor.view(*shape))\n",
    "        cumulative_size = new_cumulative_size\n",
    "    return moved_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e135711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/hep-lbdl/CaloGAN/blob/v1.0/models/architectures.py.\n",
    "# Paper: https://arxiv.org/abs/1712.10321.\n",
    "class ModelConv3(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers_0 = torch.nn.Sequential(\n",
    "            AssertShape(1, 3, 96),\n",
    "            self.make_conv_layer(1, 64, kernel=3, norm=False),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(64, 16, kernel=3, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(16, 3, 48),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(16, 8, kernel=2, padding='valid'),\n",
    "            AssertShape(8, 4, 49),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(8, 8, kernel=2, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(8, 5, 25),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(1000),\n",
    "        )\n",
    "        self.layers_1 = torch.nn.Sequential(\n",
    "            AssertShape(1, 12, 12),\n",
    "            self.make_conv_layer(1, 64, kernel=3, norm=False),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(64, 16, kernel=3, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(16, 12, 6),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(16, 8, kernel=2, padding='valid'),\n",
    "            AssertShape(8, 13, 7),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(8, 8, kernel=2, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(8, 14, 4),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(448),\n",
    "        )\n",
    "        self.layers_2 = torch.nn.Sequential(\n",
    "            AssertShape(1, 12, 6),\n",
    "            self.make_conv_layer(1, 64, kernel=3, norm=False),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(64, 16, kernel=3, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(16, 12, 3),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(16, 8, kernel=2, padding='valid'),\n",
    "            AssertShape(8, 13, 4),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(8, 8, kernel=2, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(8, 14, 3),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(336),\n",
    "        )\n",
    "        flat_size = 1000 + 448 + 336\n",
    "        self.layers_post = torch.nn.Sequential(\n",
    "            AssertShape(flat_size),\n",
    "            torch.nn.Linear(flat_size, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_conv_layer(num_in, num_out, kernel=3, norm=True, padding='same', stride=1):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(num_in, num_out, kernel, padding=padding, stride=stride),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            #torch.nn.Dropout(),\n",
    "            *([torch.nn.BatchNorm2d(num_out)] if norm else []),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0, x1, x2 = x\n",
    "        p0 = self.layers_0(x0)\n",
    "        p1 = self.layers_1(x1)\n",
    "        p2 = self.layers_2(x2)\n",
    "        p = torch.cat((p0, p1, p2), 1)\n",
    "        return self.layers_post(p)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(\n",
    "        data_a: h5py.File,\n",
    "        data_b: h5py.File,\n",
    "        begin_a: int,\n",
    "        end_a: int,\n",
    "        begin_b: int,\n",
    "        end_b: int,\n",
    "    ) -> Tuple[Any, torch.Tensor]:\n",
    "        x0_a, x1_a, x2_a = get_layers(data_a, begin_a, end_a)\n",
    "        x0_b, x1_b, x2_b = get_layers(data_b, begin_b, end_b)\n",
    "        \n",
    "        y = torch.Tensor([0] * (end_a - begin_a) + [1] * (end_b - begin_b))\n",
    "        x0 = torch.Tensor(np.vstack([x0_a, x0_b]))\n",
    "        x1 = torch.Tensor(np.vstack([x1_a, x1_b]))\n",
    "        x2 = torch.Tensor(np.vstack([x2_a, x2_b]))\n",
    "        x0, x1, x2, y = move_tensors_to([x0, x1, x2, y], dev)\n",
    "        \n",
    "        assert len(x0.shape) == len(x1.shape) == len(x2.shape) == 3\n",
    "        x0 = x0.view(x0.shape[0], 1, x0.shape[1], x0.shape[2])\n",
    "        x1 = x1.view(x1.shape[0], 1, x1.shape[1], x1.shape[2])\n",
    "        x2 = x2.view(x2.shape[0], 1, x2.shape[1], x2.shape[2])\n",
    "        assert len(x0.shape) == len(x1.shape) == len(x2.shape) == 4\n",
    "        \n",
    "        x = (x0, x1, x2)\n",
    "        return x, y\n",
    "    \n",
    "    @staticmethod\n",
    "    def description() -> str:\n",
    "        return '3-stream convolution network'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aba30ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    model,\n",
    "    alt_label,\n",
    "    num_epochs,\n",
    "    minibatch_size=128,\n",
    "    cv_split=0.1,\n",
    "):\n",
    "    data_a = data['eplus']\n",
    "    data_b = data[alt_label]\n",
    "    sampler = Sampler(\n",
    "        len(data_a['layer_0']),\n",
    "        len(data_b['layer_0']),\n",
    "        minibatch_size=minibatch_size,\n",
    "        cv_split=cv_split,\n",
    "    )\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    max_train_index_a = 0\n",
    "    max_train_index_b = 0\n",
    "    model.train()\n",
    "    while True:\n",
    "        epoch = sampler.epoch()\n",
    "        if epoch.id > num_epochs:\n",
    "            break\n",
    "\n",
    "        print(f':: Epoch {epoch.id}', flush=True)\n",
    "        for (begin_a, end_a), (begin_b, end_b) in tqdm.notebook.tqdm(epoch):\n",
    "            assert begin_a <= end_a\n",
    "            assert begin_b <= end_b\n",
    "            \n",
    "            max_train_index_a = max([max_train_index_a, end_a-1])\n",
    "            max_train_index_b = max([max_train_index_b, end_b-1])\n",
    "            opt.zero_grad()\n",
    "            x, y = model.prepare_input(data_a, data_b, begin_a, end_a, begin_b, end_b)\n",
    "            y_prob = model(x).flatten()\n",
    "            loss = F.binary_cross_entropy(y_prob, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    \n",
    "    print(':: Evaluating')\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_prob = []\n",
    "    with torch.no_grad():\n",
    "        for (begin_a, end_a), (begin_b, end_b) in tqdm.notebook.tqdm(sampler.cv()):\n",
    "            assert max_train_index_a < begin_a <= end_a\n",
    "            assert max_train_index_b < begin_b <= end_b\n",
    "            x, this_y = model.prepare_input(data_a, data_b, begin_a, end_a, begin_b, end_b)\n",
    "            this_y_prob = model(x).flatten().cpu()\n",
    "            y += list(this_y.cpu())\n",
    "            y_prob += list(this_y_prob)\n",
    "    \n",
    "    return model, y, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7816f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: torch.nn.Module):\n",
    "    # https://stackoverflow.com/a/49201237\n",
    "    return sum(param_set.numel() for param_set in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2f44709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_big_number(num: int) -> str:\n",
    "    it = iter(reversed(str(num)))\n",
    "    result = []\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            for _ in range(3):\n",
    "                result.append(next(it))\n",
    "            result.append(' ')\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "    if result[-1] == ' ':\n",
    "        result.pop()\n",
    "    return f''.join(reversed(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "21735c2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 3-stream convolution network\n",
      "Parameters: 33 945\n",
      ":: Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655b7bae3e604f2591247775b724f4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2878f6d49d8d4449a9a0af8ecfaa5cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd142b9eeef2430aa213e98e963c662f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21fba7524e44e13b73f02e68869ad26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0538634cb22e4fc298d3c31b83f8830a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1974f578360f4807ba7b963fc4977a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: FC network on pixel intensities\n",
      "Parameters: 5 122 049\n",
      ":: Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38846c3218584d71b979ed7ef281c433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8eea0dbd7c40dcb30a016ac6aac6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fae7cf98244572b378816a108e8d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc94c3837990492a8258afb54fbbace7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a26905092a7474eb381989144750518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263c01a74cb6460a8f79991304866aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "    ModelConv3().to(dev),\n",
    "    ModelFcPixel().to(dev),\n",
    "]\n",
    "num_epochs = 5\n",
    "alt_label = 'piplus'\n",
    "\n",
    "results = {}\n",
    "for model in models:\n",
    "    print(f'Model: {model.description()}')\n",
    "    print(f'Parameters: {format_big_number(count_parameters(model))}')\n",
    "    _, y, y_prob = train_and_evaluate(\n",
    "        model=model,\n",
    "        alt_label=alt_label,\n",
    "        num_epochs=num_epochs,\n",
    "    )\n",
    "    results[model.__class__.__name__] = (y, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e9bc26fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr_threshold = 1/1000\n",
    "tpr_threshold = 0.8\n",
    "\n",
    "labels = []\n",
    "handles = []\n",
    "\n",
    "for name, (y, y_prob) in results.items():\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(y, y_prob)\n",
    "    mask = (fpr > fpr_threshold) & (tpr > tpr_threshold)\n",
    "    handles += plt.plot(tpr[mask], 1/fpr[mask])\n",
    "    labels.append(name)\n",
    "\n",
    "plt.xlabel('True positive (π⁺) rate')\n",
    "plt.ylabel('1 / False positive (π⁺) rate')\n",
    "plt.legend(handles=handles, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d4a30884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConv3           ROC AUC = 0.9998033; 1/(1-ROC AUC) = 5084.2524179\n",
      "ModelFcPixel         ROC AUC = 0.9997430; 1/(1-ROC AUC) = 3890.8234928\n"
     ]
    }
   ],
   "source": [
    "for name, (y, y_prob) in results.items():\n",
    "    auc = sklearn.metrics.roc_auc_score(y, y_prob)\n",
    "    print(f'{name:20} ROC AUC = {auc:.7f}; 1/(1-ROC AUC) = {1/(1-auc):.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87011825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
