{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c059fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tqdm.notebook\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f321198",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'eplus': h5py.File('data/eplus_angle_position_5deg_xy.h5'),\n",
    "    'piplus': h5py.File('data/piplus_angle_position_5deg_xy.h5'),\n",
    "    'gamma': h5py.File('data/gamma_angle_position_5deg_xy.h5'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb84831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models will be run on a GPU (CUDA/HIP)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Models will be run on a GPU (CUDA/HIP)')\n",
    "    dev = torch.device('cuda')\n",
    "else:\n",
    "    print('Models will be run on a CPU')\n",
    "    dev = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58e2934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sizes(size_a: int, size_b: int, num_samples: int) -> Tuple[int, int]:\n",
    "    num_a_samples = min(\n",
    "        np.random.binomial(num_samples, size_a / (size_a + size_b)),\n",
    "        size_a,\n",
    "    )\n",
    "    num_b_samples = min(num_samples - num_a_samples, size_b)\n",
    "    num_a_samples = min(num_samples - num_b_samples, size_a)\n",
    "    assert num_a_samples + num_b_samples == min(num_samples, size_a + size_b)\n",
    "    return num_a_samples, num_b_samples\n",
    "\n",
    "class SamplerEpoch:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_a_indices: int,\n",
    "        num_b_indices: int,\n",
    "        minibatch_size: int,\n",
    "        id: Optional[int],\n",
    "        cursor_a: int = 0,\n",
    "        cursor_b: int = 0\n",
    "    ) -> None:\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.id = id\n",
    "        self.num_a_indices = num_a_indices\n",
    "        self.num_b_indices = num_b_indices\n",
    "        self.initial_cursor_a = cursor_a\n",
    "        self.initial_cursor_b = cursor_b\n",
    "        self.cursor_a = cursor_a\n",
    "        self.cursor_b = cursor_b\n",
    "    \n",
    "    def __iter__(self) -> 'SamplerEpoch':\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        num_a_items_left = self.num_a_indices - self.cursor_a\n",
    "        num_b_items_left = self.num_b_indices - self.cursor_b\n",
    "        assert num_a_items_left >= 0\n",
    "        assert num_b_items_left >= 0\n",
    "        \n",
    "        if num_a_items_left == num_b_items_left == 0:\n",
    "            raise StopIteration()\n",
    "\n",
    "        num_a_items, num_b_items = sample_sizes(\n",
    "            num_a_items_left,\n",
    "            num_b_items_left,\n",
    "            self.minibatch_size,\n",
    "        )\n",
    "        \n",
    "        begin_a = self.cursor_a\n",
    "        end_a = begin_a + num_a_items\n",
    "        begin_b = self.cursor_b\n",
    "        end_b = begin_b + num_b_items\n",
    "        \n",
    "        self.cursor_a = end_a\n",
    "        self.cursor_b = end_b\n",
    "        # Only the last mini-batch may be incomplete.\n",
    "        assert num_a_items + num_b_items == self.minibatch_size or (\n",
    "            self.cursor_a == self.num_a_indices\n",
    "            and self.cursor_b == self.num_b_indices\n",
    "        )\n",
    "        return (begin_a, end_a), (begin_b, end_b)\n",
    "    \n",
    "    def __len__(self):\n",
    "        num_indices = self.num_a_indices + self.num_b_indices - self.initial_cursor_a - self.initial_cursor_b\n",
    "        batch = self.minibatch_size\n",
    "        return (num_indices + batch - 1) // batch\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f'SamplerEpoch(id={self.id}), '\n",
    "            f'minibatch_size={self.minibatch_size}, '\n",
    "            f'num_indices=({self.num_a_indices}, {self.num_b_indices}), '\n",
    "            f'cursor=({self.cursor_a}, {self.cursor_b}))'\n",
    "        )\n",
    "\n",
    "class Sampler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_samples_a: int,\n",
    "        num_samples_b: int,\n",
    "        minibatch_size: int,\n",
    "        cv_split: float,\n",
    "    ) -> None:\n",
    "        while True:\n",
    "            num_cv_indices_a = round(num_samples_a * cv_split)\n",
    "            num_cv_indices_b = round(num_samples_b * cv_split)\n",
    "            self.cv_start_a = num_samples_a - num_cv_indices_a\n",
    "            self.cv_start_b = num_samples_b - num_cv_indices_b\n",
    "            if (self.cv_start_a + self.cv_start_b) % minibatch_size == 1:\n",
    "                cv_split *= 0.9999\n",
    "            else:\n",
    "                break\n",
    "        self.num_samples_a = num_samples_a\n",
    "        self.num_samples_b = num_samples_b\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.num_epochs = 0\n",
    "    \n",
    "    def epoch(self) -> SamplerEpoch:\n",
    "        self.num_epochs += 1\n",
    "        return SamplerEpoch(\n",
    "            self.cv_start_a,\n",
    "            self.cv_start_a,\n",
    "            minibatch_size=self.minibatch_size,\n",
    "            id=self.num_epochs,\n",
    "        )\n",
    "    \n",
    "    def cv(self) -> SamplerEpoch:\n",
    "        return SamplerEpoch(\n",
    "            self.num_samples_a,\n",
    "            self.num_samples_b,\n",
    "            minibatch_size=self.minibatch_size,\n",
    "            id=None,\n",
    "            cursor_a=self.cv_start_a,\n",
    "            cursor_b=self.cv_start_b,\n",
    "        )\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f'Sampler(cv_start=({self.cv_start_a}, {self.cv_start_b}), '\n",
    "            f'num_samples=({self.num_samples_a}, {self.num_samples_b}), '\n",
    "            f'minibatch_size={self.minibatch_size}, '\n",
    "            f'self.num_epochs={self.num_epochs})'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "794b443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def get_layers(data_file: h5py.File, begin: int, end: int) -> List[np.ndarray]:\n",
    "    layers = []\n",
    "    for i in range(3):\n",
    "        layer = data_file[f'layer_{i}']\n",
    "        layer_part = layer[begin:end]\n",
    "        layers.append(layer_part)\n",
    "    return layers\n",
    "\n",
    "def flatten_layers(data_file: h5py.File, begin: int, end: int) -> np.ndarray:\n",
    "    layers = get_layers(data_file, begin, end)\n",
    "    \n",
    "    for i, layer in enumerate(layers):\n",
    "        feature_size = reduce(lambda a, b: a * b, layer.shape[1:])\n",
    "        reshaped = layer.reshape((layer.shape[0], feature_size))\n",
    "        layers[i] = reshaped\n",
    "        \n",
    "    return np.hstack(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7feb0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod, ABC\n",
    "\n",
    "class BaseModel(torch.nn.Module, ABC):\n",
    "    @abstractmethod\n",
    "    def prepare_input(\n",
    "        self,\n",
    "        data_a: h5py.File,\n",
    "        data_b: h5py.File,\n",
    "        begin_a: int,\n",
    "        end_a: int,\n",
    "        begin_b: int,\n",
    "        end_b: int,\n",
    "    ) -> Tuple[Any, torch.Tensor]:\n",
    "        \"\"\"Prepare input data from the dataset slices and return tensors `X` and `y` on `dev`.\"\"\"\n",
    "        ...\n",
    "    \n",
    "    @abstractmethod\n",
    "    def description(self) -> str:\n",
    "        \"\"\"Briefly describe this model.\"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7419fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFcPixel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            self.make_layer(504, 512),\n",
    "            self.make_layer(512, 1024),\n",
    "            self.make_layer(1024, 2048),\n",
    "            self.make_layer(2048, 1024),\n",
    "            self.make_layer(1024, 128),\n",
    "            torch.nn.Linear(128, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_layer(num_in, num_out):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_in, num_out),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.BatchNorm1d(num_out),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(\n",
    "        data_a: h5py.File,\n",
    "        data_b: h5py.File,\n",
    "        begin_a: int,\n",
    "        end_a: int,\n",
    "        begin_b: int,\n",
    "        end_b: int,\n",
    "    ) -> Tuple[Any, torch.Tensor]:\n",
    "        x_a = flatten_layers(data_a, begin_a, end_a)\n",
    "        x_b = flatten_layers(data_b, begin_b, end_b)\n",
    "        x = torch.Tensor(np.vstack([x_a, x_b])).to(dev)\n",
    "        y = torch.Tensor([0] * (end_a - begin_a) + [1] * (end_b - begin_b)).to(dev)\n",
    "        return x, y\n",
    "    \n",
    "    @staticmethod\n",
    "    def description() -> str:\n",
    "        return 'FC network on pixel intensities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e55ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssertShape(torch.nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super().__init__()\n",
    "        self.required_shape = torch.Size(shape)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        actual_shape = x.shape[1:]\n",
    "        if actual_shape != self.required_shape:\n",
    "            raise ValueError(f'Invalid shape: expected {self.required_shape}, got {actual_shape}')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c3a8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy => (400000, 1)\n",
      "layer_0 => (400000, 3, 96)\n",
      "layer_1 => (400000, 12, 12)\n",
      "layer_2 => (400000, 12, 6)\n",
      "overflow => (400000, 3)\n",
      "px => (400000, 1)\n",
      "py => (400000, 1)\n",
      "pz => (400000, 1)\n",
      "t0 => (400000, 1)\n",
      "x0 => (400000, 1)\n",
      "y0 => (400000, 1)\n",
      "z0 => (400000, 1)\n"
     ]
    }
   ],
   "source": [
    "for key, value in data['eplus'].items():\n",
    "    print(f'{key} => {value.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96c99cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def move_tensors_to(tensors, device):\n",
    "    shapes = [tensor.shape for tensor in tensors]\n",
    "    all_flat = torch.cat([tensor.flatten() for tensor in tensors], 0)\n",
    "    all_flat = all_flat.to(device)\n",
    "    sizes = [reduce(lambda a, b: a * b, shape) for shape in shapes]\n",
    "    \n",
    "    moved_tensors = []\n",
    "    cumulative_size = 0\n",
    "    for shape, size in zip(shapes, sizes):\n",
    "        new_cumulative_size = cumulative_size + size\n",
    "        flat_tensor = all_flat[cumulative_size:new_cumulative_size]\n",
    "        moved_tensors.append(flat_tensor.view(*shape))\n",
    "        cumulative_size = new_cumulative_size\n",
    "    return moved_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6451afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatResidual(torch.nn.Module):\n",
    "    def __init__(self, inner: torch.nn.Module) -> None:\n",
    "        super().__init__()\n",
    "        self.inner = inner\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_add = self.inner(x)\n",
    "        assert len(x_add.shape) == len(x.shape)\n",
    "        \n",
    "        channel_axis = 1\n",
    "        for i in range(len(x.shape)):\n",
    "            if i != channel_axis and x_add.shape[i] != x.shape[i]:\n",
    "                raise Exception(f'Concat shape mismatch: {x_add.shape} vs {x.shape}')\n",
    "                \n",
    "        return torch.cat([x, x_add], channel_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e135711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/hep-lbdl/CaloGAN/blob/v1.0/models/architectures.py.\n",
    "# Paper: https://arxiv.org/abs/1712.10321.\n",
    "class ModelConv3(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers_0 = torch.nn.Sequential(\n",
    "            AssertShape(1, 3, 96),\n",
    "            self.make_conv_layer(1, 64, kernel=3, norm=False),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(64, 16, kernel=3, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(16, 3, 48),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(16, 8, kernel=2, padding='valid'),\n",
    "            AssertShape(8, 4, 49),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(8, 8, kernel=2, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(8, 5, 25),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(1000),\n",
    "        )\n",
    "        self.layers_1 = torch.nn.Sequential(\n",
    "            AssertShape(1, 12, 12),\n",
    "            self.make_conv_layer(1, 64, kernel=3, norm=False),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(64, 16, kernel=3, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(16, 12, 6),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(16, 8, kernel=2, padding='valid'),\n",
    "            AssertShape(8, 13, 7),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(8, 8, kernel=2, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(8, 14, 4),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(448),\n",
    "        )\n",
    "        self.layers_2 = torch.nn.Sequential(\n",
    "            AssertShape(1, 12, 6),\n",
    "            self.make_conv_layer(1, 64, kernel=3, norm=False),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(64, 16, kernel=3, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(16, 12, 3),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(16, 8, kernel=2, padding='valid'),\n",
    "            AssertShape(8, 13, 4),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(8, 8, kernel=2, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(8, 14, 3),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(336),\n",
    "        )\n",
    "        flat_size = 1000 + 448 + 336\n",
    "        self.layers_post = torch.nn.Sequential(\n",
    "            AssertShape(flat_size),\n",
    "            torch.nn.Linear(flat_size, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_conv_layer(num_in, num_out, kernel=3, norm=True, padding='same', stride=1):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(num_in, num_out, kernel, padding=padding, stride=stride),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            #torch.nn.Dropout(),\n",
    "            *([torch.nn.BatchNorm2d(num_out)] if norm else []),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0, x1, x2 = x\n",
    "        p0 = self.layers_0(x0)\n",
    "        p1 = self.layers_1(x1)\n",
    "        p2 = self.layers_2(x2)\n",
    "        p = torch.cat((p0, p1, p2), 1)\n",
    "        return self.layers_post(p)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(\n",
    "        data_a: h5py.File,\n",
    "        data_b: h5py.File,\n",
    "        begin_a: int,\n",
    "        end_a: int,\n",
    "        begin_b: int,\n",
    "        end_b: int,\n",
    "    ) -> Tuple[Any, torch.Tensor]:\n",
    "        x0_a, x1_a, x2_a = get_layers(data_a, begin_a, end_a)\n",
    "        x0_b, x1_b, x2_b = get_layers(data_b, begin_b, end_b)\n",
    "        \n",
    "        y = torch.Tensor([0] * (end_a - begin_a) + [1] * (end_b - begin_b))\n",
    "        x0 = torch.Tensor(np.vstack([x0_a, x0_b]))\n",
    "        x1 = torch.Tensor(np.vstack([x1_a, x1_b]))\n",
    "        x2 = torch.Tensor(np.vstack([x2_a, x2_b]))\n",
    "        x0, x1, x2, y = move_tensors_to([x0, x1, x2, y], dev)\n",
    "        \n",
    "        assert len(x0.shape) == len(x1.shape) == len(x2.shape) == 3\n",
    "        x0 = x0.view(x0.shape[0], 1, x0.shape[1], x0.shape[2])\n",
    "        x1 = x1.view(x1.shape[0], 1, x1.shape[1], x1.shape[2])\n",
    "        x2 = x2.view(x2.shape[0], 1, x2.shape[1], x2.shape[2])\n",
    "        assert len(x0.shape) == len(x1.shape) == len(x2.shape) == 4\n",
    "        \n",
    "        x = (x0, x1, x2)\n",
    "        return x, y\n",
    "    \n",
    "    @staticmethod\n",
    "    def description() -> str:\n",
    "        return '3-stream convolution network'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f75779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://github.com/hep-lbdl/CaloGAN/blob/v1.0/models/architectures.py.\n",
    "# Paper: https://arxiv.org/abs/1712.10321.\n",
    "class ModelConv3(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers_0 = torch.nn.Sequential(\n",
    "            AssertShape(1, 3, 96),\n",
    "            self.make_conv_layer(1, 64, kernel=3, norm=False),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(64, 16, kernel=3, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(16, 3, 48),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(16, 8, kernel=2, padding='valid'),\n",
    "            AssertShape(8, 4, 49),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(8, 8, kernel=2, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(8, 5, 25),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(1000),\n",
    "        )\n",
    "        self.layers_1 = torch.nn.Sequential(\n",
    "            AssertShape(1, 12, 12),\n",
    "            self.make_conv_layer(1, 64, kernel=3, norm=False),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(64, 16, kernel=3, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(16, 12, 6),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(16, 8, kernel=2, padding='valid'),\n",
    "            AssertShape(8, 13, 7),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(8, 8, kernel=2, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(8, 14, 4),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(448),\n",
    "        )\n",
    "        self.layers_2 = torch.nn.Sequential(\n",
    "            AssertShape(1, 12, 6),\n",
    "            self.make_conv_layer(1, 64, kernel=3, norm=False),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(64, 16, kernel=3, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(16, 12, 3),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(16, 8, kernel=2, padding='valid'),\n",
    "            AssertShape(8, 13, 4),\n",
    "            \n",
    "            torch.nn.ZeroPad2d(1),\n",
    "            self.make_conv_layer(8, 8, kernel=2, padding='valid', stride=(1, 2)),\n",
    "            AssertShape(8, 14, 3),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(336),\n",
    "        )\n",
    "        flat_size = 1000 + 448 + 336\n",
    "        self.layers_post = torch.nn.Sequential(\n",
    "            AssertShape(flat_size),\n",
    "            torch.nn.Linear(flat_size, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_conv_layer(num_in, num_out, kernel=3, norm=True, padding='same', stride=1):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(num_in, num_out, kernel, padding=padding, stride=stride),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            #torch.nn.Dropout(),\n",
    "            *([torch.nn.BatchNorm2d(num_out)] if norm else []),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0, x1, x2 = x\n",
    "        p0 = self.layers_0(x0)\n",
    "        p1 = self.layers_1(x1)\n",
    "        p2 = self.layers_2(x2)\n",
    "        p = torch.cat((p0, p1, p2), 1)\n",
    "        return self.layers_post(p)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(\n",
    "        data_a: h5py.File,\n",
    "        data_b: h5py.File,\n",
    "        begin_a: int,\n",
    "        end_a: int,\n",
    "        begin_b: int,\n",
    "        end_b: int,\n",
    "    ) -> Tuple[Any, torch.Tensor]:\n",
    "        x0_a, x1_a, x2_a = get_layers(data_a, begin_a, end_a)\n",
    "        x0_b, x1_b, x2_b = get_layers(data_b, begin_b, end_b)\n",
    "        \n",
    "        y = torch.Tensor([0] * (end_a - begin_a) + [1] * (end_b - begin_b))\n",
    "        x0 = torch.Tensor(np.vstack([x0_a, x0_b]))\n",
    "        x1 = torch.Tensor(np.vstack([x1_a, x1_b]))\n",
    "        x2 = torch.Tensor(np.vstack([x2_a, x2_b]))\n",
    "        x0, x1, x2, y = move_tensors_to([x0, x1, x2, y], dev)\n",
    "        \n",
    "        assert len(x0.shape) == len(x1.shape) == len(x2.shape) == 3\n",
    "        x0 = x0.view(x0.shape[0], 1, x0.shape[1], x0.shape[2])\n",
    "        x1 = x1.view(x1.shape[0], 1, x1.shape[1], x1.shape[2])\n",
    "        x2 = x2.view(x2.shape[0], 1, x2.shape[1], x2.shape[2])\n",
    "        assert len(x0.shape) == len(x1.shape) == len(x2.shape) == 4\n",
    "        \n",
    "        x = (x0, x1, x2)\n",
    "        return x, y\n",
    "    \n",
    "    @staticmethod\n",
    "    def description() -> str:\n",
    "        return '3-stream convolution network'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "814c39fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper: https://arxiv.org/abs/1608.06993\n",
    "class ModelDenseNet3(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Growth rate.\n",
    "        k = self.k = 8\n",
    "        \n",
    "        self.layers_0 = torch.nn.Sequential(\n",
    "            AssertShape(1, 3, 96),\n",
    "            self.make_densenet_layer(1, k - 1),\n",
    "            \n",
    "            self.make_densenet_layer(k, k),\n",
    "            self.make_transition_layer(2 * k, stride=(1, 2)),\n",
    "            AssertShape(2 * k, 3, 48),\n",
    "            \n",
    "            self.make_densenet_layer(2 * k, k),\n",
    "            self.make_transition_layer(3 * k, stride=(1, 2)),\n",
    "            AssertShape(3 * k, 3, 24),\n",
    "            \n",
    "            self.make_densenet_layer(3 * k, k),\n",
    "            self.make_transition_layer(4 * k, stride=(1, 2)),\n",
    "            AssertShape(4 * k, 3, 12),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(144 * k),\n",
    "            torch.nn.Linear(144 * k, 100),\n",
    "            torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layers_1 = torch.nn.Sequential(\n",
    "            AssertShape(1, 12, 12),\n",
    "            self.make_densenet_layer(1, k - 1),\n",
    "            \n",
    "            self.make_densenet_layer(k, k),\n",
    "            self.make_transition_layer(2 * k, stride=2),\n",
    "            AssertShape(2 * k, 6, 6),\n",
    "            \n",
    "            self.make_densenet_layer(2 * k, k),\n",
    "            self.make_densenet_layer(3 * k, k),\n",
    "            self.make_transition_layer(4 * k, stride=2),\n",
    "            AssertShape(4 * k, 3, 3),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(36 * k),\n",
    "            torch.nn.Linear(36 * k, 80),\n",
    "            torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.layers_2 = torch.nn.Sequential(\n",
    "            AssertShape(1, 12, 6),\n",
    "            self.make_densenet_layer(1, k - 1),\n",
    "            \n",
    "            self.make_densenet_layer(k, k),\n",
    "            self.make_transition_layer(2 * k, stride=(2, 1)),\n",
    "            AssertShape(2 * k, 6, 6),\n",
    "            \n",
    "            self.make_densenet_layer(2 * k, k),\n",
    "            self.make_densenet_layer(3 * k, k),\n",
    "            self.make_transition_layer(4 * k, stride=2),\n",
    "            AssertShape(4 * k, 3, 3),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            AssertShape(36 * k),\n",
    "            torch.nn.Linear(36 * k, 80),\n",
    "            torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        flat_size = 100 + 80 + 80\n",
    "        self.layers_post = torch.nn.Sequential(\n",
    "            AssertShape(flat_size),\n",
    "            torch.nn.Linear(flat_size, 300),\n",
    "            torch.nn.BatchNorm1d(300),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(300, 1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def make_densenet_layer(self, num_in, num_add, kernel=3):\n",
    "        submodule = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm2d(num_in),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(num_in, num_add, kernel, padding='same'),\n",
    "        )\n",
    "        return ConcatResidual(submodule)\n",
    "    \n",
    "    def make_transition_layer(self, num_channels, stride):\n",
    "        return torch.nn.AvgPool2d(stride)\n",
    "    \n",
    "        # The following does not perform better.\n",
    "        \n",
    "        #return torch.nn.Sequential(\n",
    "        #    torch.nn.BatchNorm2d(num_channels),\n",
    "        #    torch.nn.LeakyReLU(),\n",
    "        #    torch.nn.Conv2d(num_channels, num_channels, 3, stride=stride, padding=1),\n",
    "        #)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0, x1, x2 = x\n",
    "        p0 = self.layers_0(x0)\n",
    "        p1 = self.layers_1(x1)\n",
    "        p2 = self.layers_2(x2)\n",
    "        p = torch.cat((p0, p1, p2), 1)\n",
    "        return self.layers_post(p)\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(\n",
    "        data_a: h5py.File,\n",
    "        data_b: h5py.File,\n",
    "        begin_a: int,\n",
    "        end_a: int,\n",
    "        begin_b: int,\n",
    "        end_b: int,\n",
    "    ) -> Tuple[Any, torch.Tensor]:\n",
    "        x0_a, x1_a, x2_a = get_layers(data_a, begin_a, end_a)\n",
    "        x0_b, x1_b, x2_b = get_layers(data_b, begin_b, end_b)\n",
    "        \n",
    "        y = torch.Tensor([0] * (end_a - begin_a) + [1] * (end_b - begin_b))\n",
    "        x0 = torch.Tensor(np.vstack([x0_a, x0_b]))\n",
    "        x1 = torch.Tensor(np.vstack([x1_a, x1_b]))\n",
    "        x2 = torch.Tensor(np.vstack([x2_a, x2_b]))\n",
    "        x0, x1, x2, y = move_tensors_to([x0, x1, x2, y], dev)\n",
    "        \n",
    "        assert len(x0.shape) == len(x1.shape) == len(x2.shape) == 3\n",
    "        x0 = x0.view(x0.shape[0], 1, x0.shape[1], x0.shape[2])\n",
    "        x1 = x1.view(x1.shape[0], 1, x1.shape[1], x1.shape[2])\n",
    "        x2 = x2.view(x2.shape[0], 1, x2.shape[1], x2.shape[2])\n",
    "        assert len(x0.shape) == len(x1.shape) == len(x2.shape) == 4\n",
    "        \n",
    "        x = (x0, x1, x2)\n",
    "        return x, y\n",
    "    \n",
    "    @staticmethod\n",
    "    def description() -> str:\n",
    "        return '3-stream DenseNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "aba30ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    model,\n",
    "    alt_label,\n",
    "    num_epochs,\n",
    "    minibatch_size=128,\n",
    "    cv_split=0.1,\n",
    "):\n",
    "    data_a = data['eplus']\n",
    "    data_b = data[alt_label]\n",
    "    sampler = Sampler(\n",
    "        len(data_a['layer_0']),\n",
    "        len(data_b['layer_0']),\n",
    "        minibatch_size=minibatch_size,\n",
    "        cv_split=cv_split,\n",
    "    )\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    max_train_index_a = 0\n",
    "    max_train_index_b = 0\n",
    "    model.train()\n",
    "    while True:\n",
    "        epoch = sampler.epoch()\n",
    "        if epoch.id > num_epochs:\n",
    "            break\n",
    "\n",
    "        print(f':: Epoch {epoch.id}', flush=True)\n",
    "        for (begin_a, end_a), (begin_b, end_b) in tqdm.notebook.tqdm(epoch):\n",
    "            assert begin_a <= end_a\n",
    "            assert begin_b <= end_b\n",
    "            \n",
    "            max_train_index_a = max([max_train_index_a, end_a-1])\n",
    "            max_train_index_b = max([max_train_index_b, end_b-1])\n",
    "            opt.zero_grad()\n",
    "            x, y = model.prepare_input(data_a, data_b, begin_a, end_a, begin_b, end_b)\n",
    "            y_prob = model(x).flatten()\n",
    "            loss = F.binary_cross_entropy(y_prob, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "    \n",
    "    print(':: Evaluating')\n",
    "    model.eval()\n",
    "    y = []\n",
    "    y_prob = []\n",
    "    with torch.no_grad():\n",
    "        for (begin_a, end_a), (begin_b, end_b) in tqdm.notebook.tqdm(sampler.cv()):\n",
    "            assert max_train_index_a < begin_a <= end_a\n",
    "            assert max_train_index_b < begin_b <= end_b\n",
    "            x, this_y = model.prepare_input(data_a, data_b, begin_a, end_a, begin_b, end_b)\n",
    "            this_y_prob = model(x).flatten().cpu()\n",
    "            y += list(this_y.cpu())\n",
    "            y_prob += list(this_y_prob)\n",
    "    \n",
    "    return model, y, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7816f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: torch.nn.Module):\n",
    "    # https://stackoverflow.com/a/49201237\n",
    "    return sum(param_set.numel() for param_set in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "2f44709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_big_number(num: int) -> str:\n",
    "    it = iter(reversed(str(num)))\n",
    "    result = []\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            for _ in range(3):\n",
    "                result.append(next(it))\n",
    "            result.append(' ')\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "    if result[-1] == ' ':\n",
    "        result.pop()\n",
    "    return f''.join(reversed(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "21735c2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 3-stream DenseNet\n",
      "Parameters: 251 685\n",
      ":: Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e29fe76eb29455aa0d6131b0f74b059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b15fd65fbe4b789d90c3b56ea5fcac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e790ca3dc824a069f07a02300780cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 3-stream convolution network\n",
      "Parameters: 33 945\n",
      ":: Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496c7afc0c824540a0d9b13279d4ed1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb44d88d64d4d0ab3119b540c50ec6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc85413e9fea4b7a87ee18bf6b864654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: FC network on pixel intensities\n",
      "Parameters: 5 122 049\n",
      ":: Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60eb62ff02c4ae29df6dd6ccb47c1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2c94ffa38b471690fa5e54832f9363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48a0c9430794a448317ea61c5ec2e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "    ModelDenseNet3().to(dev),\n",
    "    ModelConv3().to(dev),\n",
    "    ModelFcPixel().to(dev),\n",
    "]\n",
    "num_epochs = 2\n",
    "alt_label = 'piplus'\n",
    "\n",
    "results = {}\n",
    "for model in models:\n",
    "    print(f'Model: {model.description()}')\n",
    "    print(f'Parameters: {format_big_number(count_parameters(model))}')\n",
    "    _, y, y_prob = train_and_evaluate(\n",
    "        model=model,\n",
    "        alt_label=alt_label,\n",
    "        num_epochs=num_epochs,\n",
    "    )\n",
    "    results[model.__class__.__name__] = (y, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e9bc26fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr_threshold = 1/3000\n",
    "tpr_threshold = 0.85\n",
    "\n",
    "labels = []\n",
    "handles = []\n",
    "\n",
    "for name, (y, y_prob) in results.items():\n",
    "    fpr, tpr, _ = sklearn.metrics.roc_curve(y, y_prob)\n",
    "    mask = (fpr > fpr_threshold) & (tpr > tpr_threshold)\n",
    "    handles += plt.plot(tpr[mask], 1/fpr[mask])\n",
    "    labels.append(name)\n",
    "\n",
    "plt.xlabel('True positive (π⁺) rate')\n",
    "plt.ylabel('1 / False positive (π⁺) rate')\n",
    "plt.legend(handles=handles, labels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d4a30884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelDenseNet3       ROC AUC = 0.9998656; 1/(1-ROC AUC) = 7440.5038709\n",
      "ModelConv3           ROC AUC = 0.9997553; 1/(1-ROC AUC) = 4087.3424202\n",
      "ModelFcPixel         ROC AUC = 0.9994904; 1/(1-ROC AUC) = 1962.1385741\n"
     ]
    }
   ],
   "source": [
    "for name, (y, y_prob) in results.items():\n",
    "    auc = sklearn.metrics.roc_auc_score(y, y_prob)\n",
    "    print(f'{name:20} ROC AUC = {auc:.7f}; 1/(1-ROC AUC) = {1/(1-auc):.7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87011825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
